{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67beb2-69cb-411b-950a-a42fcbf036fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49b653-f745-4635-8dc2-32efc76e1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback(): order = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb3852-a655-4be9-bb63-bba3e61e482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cdaba1-4fb9-492a-9840-98a42a5ff8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cbs(cbs, method_nm, learn=None):\n",
    "    #set_trace()\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        if method is not None: method(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9005e8-e05c-4a9d-a5a8-2809550ef17d",
   "metadata": {},
   "source": [
    "#### **Explanation for the `sorted` mechanism**\n",
    "There are a lot going on here `sorted(cbs, key=attrgetter('order')`, in the sorted function, `attrgetter('order')` returns a function for the `sorted` then sorted uses this function for sorting callbacks which are class instances e.g:\n",
    "\n",
    "```Python\n",
    "class MyClass():      \n",
    "    order = 0\n",
    "    \n",
    "# Create instance of MyClass\n",
    "obj = MyClass()\n",
    "\n",
    "# Import the attrgetter function from the operator module\n",
    "from operator import attrgetter\n",
    "\n",
    "# Use attrgetter to get the 'order' attribute from a instance\n",
    "get_order = attrgetter('order')\n",
    "\n",
    "# Get the 'order' attribute from objects\n",
    "order = get_order(obj)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(order)  # Output: 0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb242a7-c1c8-462b-af36-f7a55da7779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompletionCB(Callback):\n",
    "    def before_fit(self, learn): self.count = 0\n",
    "    def after_batch(self, learn): self.count += 1\n",
    "    def after_fit(self, learn): print(f'Completed {self.count} batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e88e910-7520-4523-9a2f-85730810515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 batches\n"
     ]
    }
   ],
   "source": [
    "cbs =[CompletionCB()]\n",
    "run_cbs(cbs, 'before_fit')\n",
    "run_cbs(cbs, 'after_batch')\n",
    "run_cbs(cbs, 'after_fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad953d9-d7fa-4849-bd89-defd5431b760",
   "metadata": {},
   "source": [
    "#### **Understand `run_cbs` by calling callbacks step by step below**\n",
    "Note:`getattr(cb,'before_fit')(None)` syntax is not the same with the one in the recording because I'm using the latest `run_cbs` function that is updated by JH after the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73336f8-2e12-40ef-bfec-a8be377b4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = cbs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a95cfd-998f-48ff-bbe0-83d0f9dd0a5e",
   "metadata": {},
   "source": [
    "`getattr` returns a method and it is called in the the `run_cbs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a34579-3ed0-407b-99e6-df628e545caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(cb,'before_fit')(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ad0a5-9049-4b75-ac39-94f2f99c85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(cb,'after_batch')(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9fd80a-cb35-4e03-b2a1-8d62faf457cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 batches\n"
     ]
    }
   ],
   "source": [
    "getattr(cb,'after_fit')(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f3c95-5056-4f23-ad19-0e8a74bd6c89",
   "metadata": {},
   "source": [
    "as expected `self.count` line called only one time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026df977-c211-422e-8464-71d0345eef99",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "#### **with_cbs**\n",
    "the explanation decorators in the `Learner` class is  in Lesson 15 around 1:28,\n",
    "`o` in the code is I think is `self` that means Learner Class itself.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204c14d-2cc6-4b94-b94c-c21d2f647b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class with_cbs:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            #print(o)\n",
    "            try:\n",
    "                o.callback(f'before_{self.nm}')\n",
    "                # this `o` is `self`\n",
    "                f(o, *args, **kwargs)\n",
    "                o.callback(f'after_{self.nm}')\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "            finally: o.callback(f'cleanup_{self.nm}')\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9156f-c86e-47a1-88c8-c11ff96d4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a7459-6bf0-4204-8a47-10683b3e339d",
   "metadata": {},
   "source": [
    "### **Updated version  Learner class**\n",
    "Updated version of the Learner class as  it is in the original notebook. I skipped previous versions that seen it the video and earlier examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6686a2b-1864-4dcb-a26c-c8f871f310f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae2ba5-1de0-49be-be2b-d250bc32f667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.no_grad>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292423a-e983-4c8c-a984-6cda537c3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #|export\n",
    "# class Learner():\n",
    "#     def __init__(self, model, dls=(0,), loss_func=F.mse_loss, lr=0.1, cbs=None, opt_func=optim.SGD):\n",
    "#         #check below for fc.L(cbs)\n",
    "#         cbs = fc.L(cbs)\n",
    "#         fc.store_attr()\n",
    "\n",
    "#     @with_cbs('batch')\n",
    "#     def _one_batch(self):\n",
    "#         self.predict()\n",
    "#         self.callback('after_predict')\n",
    "#         self.get_loss()\n",
    "#         self.callback('after_loss')\n",
    "#         if self.training:\n",
    "#             self.backward()\n",
    "#             self.callback('after_backward')\n",
    "#             self.step()\n",
    "#             self.callback('after_step')\n",
    "#             self.zero_grad()\n",
    "\n",
    "#     @with_cbs('epoch')\n",
    "#     def _one_epoch(self):\n",
    "#         for self.iter,self.batch in enumerate(self.dl): self._one_batch()\n",
    "\n",
    "#     def one_epoch(self, training):\n",
    "#         self.model.train(training) # this 'train' comes from torch/nn/modules/module.py\n",
    "#         self.dl = self.dls.train if training else self.dls.valid\n",
    "#         self._one_epoch()\n",
    "\n",
    "#     @with_cbs('fit')\n",
    "#     def _fit(self, train, valid):\n",
    "#         for self.epoch in self.epochs:\n",
    "#             if train: self.one_epoch(True)\n",
    "#             if valid: torch.no_grad()(self.one_epoch)(False) #wow what is going on here? No `with` statement.\n",
    "\n",
    "#     def fit(self, n_epochs=1, train=True, valid=True, cbs=None, lr=None):\n",
    "#         print(cbs)\n",
    "#         #this is changes the 'None' to empty list but makes the code a bit less readable for me.\n",
    "#         cbs = fc.L(cbs)\n",
    "#         print(cbs)\n",
    "#         # `add_cb` and `rm_cb` were added in lesson 18\n",
    "#         for cb in cbs: self.cbs.append(cb)\n",
    "#         try:\n",
    "#             self.n_epochs = n_epochs # is it redundant?\n",
    "#             self.epochs = range(n_epochs)\n",
    "#             if lr is None: lr = self.lr\n",
    "#             if self.opt_func: self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "#             self._fit(train, valid)\n",
    "#         finally:\n",
    "#             for cb in cbs: self.cbs.remove(cb)\n",
    "\n",
    "#     def __getattr__(self, name):\n",
    "#         if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback, name)\n",
    "#         raise AttributeError(name)\n",
    "\n",
    "#     def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "    \n",
    "#     @property\n",
    "#     def training(self): return self.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600443b-3528-4f4f-bf1c-2b2563aadda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Learner():\n",
    "    def __init__(self, model, dls=(0,), loss_func=F.mse_loss, lr=0.1, cbs=None, opt_func=optim.SGD):\n",
    "        #check below for fc.L(cbs)\n",
    "        cbs = fc.L(cbs)\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def fit(self, n_epochs=1, train=True, valid=True, cbs=None, lr=None):\n",
    "    #print(cbs)\n",
    "    #this is changes the 'None' to empty list but makes the code a bit less readable for me.\n",
    "        cbs = fc.L(cbs)\n",
    "        #print(cbs)\n",
    "        # `add_cb` and `rm_cb` were added in lesson 18\n",
    "        for cb in cbs: self.cbs.append(cb)\n",
    "        try:\n",
    "            self.n_epochs = n_epochs # is it redundant?\n",
    "            self.epochs = range(n_epochs)\n",
    "            if lr is None: lr = self.lr\n",
    "            if self.opt_func: self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "            self._fit(train, valid)\n",
    "        finally:\n",
    "            for cb in cbs: self.cbs.remove(cb)\n",
    "        \n",
    "    @with_cbs('fit')\n",
    "    def _fit(self, train, valid):\n",
    "        for self.epoch in self.epochs:\n",
    "            if train: self.one_epoch(True)\n",
    "            if valid: torch.no_grad()(self.one_epoch)(False) #wow what is going on here? No `with` statement. \n",
    "\n",
    "    def one_epoch(self, training):\n",
    "        self.model.train(training) # this 'train' comes from torch/nn/modules/module.py\n",
    "        self.dl = self.dls.train if training else self.dls.valid\n",
    "        self._one_epoch()\n",
    "        \n",
    "    @with_cbs('epoch')\n",
    "    def _one_epoch(self):\n",
    "        for self.iter,self.batch in enumerate(self.dl): self._one_batch()        \n",
    "        \n",
    "    @with_cbs('batch')\n",
    "    def _one_batch(self):\n",
    "        self.predict()\n",
    "        self.callback('after_predict')\n",
    "        self.get_loss()\n",
    "        self.callback('after_loss')\n",
    "        if self.training:\n",
    "            self.backward()\n",
    "            self.callback('after_backward')\n",
    "            self.step()\n",
    "            self.callback('after_step')\n",
    "            self.zero_grad()\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "    \n",
    "    @property\n",
    "    def training(self): return self.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054325b-8796-41d0-ae05-d9c4ddbff435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn,tensor\n",
    "from datasets import load_dataset\n",
    "from miniai.datasets import *\n",
    "import fastcore.all as fc\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a815ad-44b1-4e8e-8343-0a89a47d81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e839c-da4d-4362-87fc-f52391837fb0",
   "metadata": {},
   "source": [
    "#### **To test CompletionCB we need a dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d09ee4-9457-42b8-81b3-d67a259b9363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/niyazi/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4b133c75ff47a9821d3035cc9c52b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = 'image','label'\n",
    "name = \"fashion_mnist\"\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e98059-27c5-4bca-8d8f-2a1908064a45",
   "metadata": {},
   "source": [
    "___\n",
    "**this is explained previously ---->>>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7054a6-51d5-480c-8677-6df1f602e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b): b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c589ee-3d10-44de-8538-3a7f0873fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "tds = dsd.with_transform(transformi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa99b6d-2de6-4ea0-9882-554b20328119",
   "metadata": {},
   "source": [
    "**<<<---- this is explained previously**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a9251-3cd4-48a8-a3ec-d51a1c3c4ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dd(tds, bs, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb5adb-eae2-480a-998a-eb147197b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,nh = 28*28,50\n",
    "def get_model(): return nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1fd04-3a79-42c5-a1b6-601c7ba27789",
   "metadata": {},
   "source": [
    "#### **Here after one epoch we have 64 batches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c9a386-9dba-437e-bfb7-0cbd402fc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "learn = Learner(model,dls,F.cross_entropy, lr =0.2, cbs=[CompletionCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e663ba6-75bd-4ecc-8003-2019e5850090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 64 batches\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a1102d-c178-4011-872f-581cc7eea2df",
   "metadata": {},
   "source": [
    "#### **Now lets use exceptions**\n",
    "These are below are inherit from the type `Exception`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebfbe77-69c7-45f5-a450-02943a4813f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed801d0-904b-481b-88b2-80dc41300780",
   "metadata": {},
   "source": [
    "`SingleBatchCB`raises `CancelEpochException()` after first batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea19d7-2f26-4cf7-bc3c-51b878aa6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleBatchCB(Callback):\n",
    "    order = 1\n",
    "    def after_batch(self, learn): raise CancelEpochException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07055080-5483-4743-bb0f-c5cc429cb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "learn = Learner(model,dls,F.cross_entropy, lr =0.2, cbs=[SingleBatchCB(),CompletionCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0002d5-29b5-4f66-8059-32540b40ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2 batches\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5aaeaa-07de-4fa8-b20d-86509094dabc",
   "metadata": {},
   "source": [
    "#### **It worked**\n",
    "one for training and one for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657b0a8-bb9f-45d5-9d93-e0e907b962be",
   "metadata": {},
   "source": [
    "#### **Metrics**\n",
    "---\n",
    "**that is for explanation. Not used in the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8fd83-10de-4bd9-9b47-1f6a8f4c6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb96c0a-6617-440b-ade7-2457c946c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self): self.vals,self.ns = [],[]\n",
    "    def add(self, inp, targ=None, n=1):\n",
    "        #set_trace()\n",
    "        self.last = self.calc(inp, targ)\n",
    "        self.vals.append(self.last)\n",
    "        self.ns.append(n)\n",
    "    @property\n",
    "    def value(self):\n",
    "        ns = tensor(self.ns)\n",
    "        return (tensor(self.vals)*ns).sum()/ns.sum()\n",
    "    def calc(self, inps, targs): return inps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc7adf2-cae8-4d2e-986d-550fcd94ba54",
   "metadata": {},
   "source": [
    "honest I do not get this polimorphism that why and how we calculated loss this way.It is not for the learner but only for the sake of explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9f8d7-31ea-42ce-a868-847278d22365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(Metric):\n",
    "    def calc(self, inps, targs): return (inps==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba021ff-70d5-4f44-a26a-7faffb5a18f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.45)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc = Accuracy()\n",
    "# acc.add(tensor([0, 1, 2, 0, 1, 2]), tensor([0, 1, 1, 2, 1, 0]))\n",
    "# acc.add(tensor([1, 1, 2, 0, 1]), tensor([0, 1, 1, 2, 1]))\n",
    "# acc.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314a767-8d13-4353-aa0c-ff763edd0e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.62), 0.62)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss = Metric()\n",
    "# loss.add(0.6, n=32)\n",
    "# loss.add(0.9, n=2)\n",
    "# loss.value, round((0.6*32+0.9*2)/(32+2), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad4ace-9e83-4a00-ba27-c9052ba0e836",
   "metadata": {},
   "source": [
    "**that is for explanation. Not used in the code**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec452e-e380-4b6e-a2df-da9ba1408cdb",
   "metadata": {},
   "source": [
    "#### **Add MetricsCB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438038d-f28c-4447-9a1d-4a7d0524d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cpu(x):\n",
    "    if isinstance(x, Mapping): return {k:to_cpu(v) for k,v in x.items()}\n",
    "    if isinstance(x, list): return [to_cpu(o) for o in x]\n",
    "    if isinstance(x, tuple): return tuple(to_cpu(list(x)))\n",
    "    return x.detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b732b16c-4232-439d-a196-7bddee85a1f8",
   "metadata": {},
   "source": [
    "`learn.preds` created in the TrainCB so if you use MetricCB without TrainCB which is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec37d90-643f-4b83-88da-819bd2fb527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms: metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "\n",
    "    def _log(self, d): print(d)\n",
    "    def before_fit(self, learn): learn.metrics = self\n",
    "    def before_epoch(self, learn): [o.reset() for o in self.all_metrics.values()]\n",
    "\n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{v.compute():.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = to_cpu(learn.batch)\n",
    "        for m in self.metrics.values(): m.update(to_cpu(learn.preds), y)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a8c3a-d325-4cc7-88a9-4339a2fcaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import MulticlassAccuracy,Mean\n",
    "from copy import copy\n",
    "from miniai.conv import * #this is for def_device\n",
    "from collections.abc import Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46473ff7-e2ac-4e07-b20d-32c923f1d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceCB(Callback):\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f9ab3-432e-4ad4-a2e3-932faf7f9e21",
   "metadata": {},
   "source": [
    "note: around lesson 16 32:00 JH talks about using HF data styles dictionary and Accelerator with this Callback context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db058f98-cb0b-4930-8da7-17e618a9dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainCB(Callback):\n",
    "    def __init__(self, n_inp=1): self.n_inp = n_inp\n",
    "    def predict(self, learn): learn.preds = learn.model(*learn.batch[:self.n_inp])\n",
    "    def get_loss(self, learn): learn.loss = learn.loss_func(learn.preds, *learn.batch[self.n_inp:])\n",
    "    def backward(self, learn): learn.loss.backward()\n",
    "    def step(self, learn): learn.opt.step()\n",
    "    def zero_grad(self, learn): learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2da12-5aad-4116-ac9d-e741d803cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "learn = Learner(model, dls, F.cross_entropy, lr=0.2, cbs=[TrainCB(),DeviceCB(), metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4efb7-4a02-491c-9e7f-077f46febc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': '0.599', 'loss': '1.210', 'epoch': 0, 'train': 'train'}\n",
      "{'accuracy': '0.707', 'loss': '0.808', 'epoch': 0, 'train': 'eval'}\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6c13f-9ee0-4261-bc62-a16ba1798fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCB_bits(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        print(f'ms:{ms} type:{type(ms)},-- metrics:{metrics} type:{type(metrics)}')\n",
    "        for o in ms:            \n",
    "            metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e46169-a5c6-4dfa-84bf-c906a5b10155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms:(<torcheval.metrics.classification.accuracy.MulticlassAccuracy object>,) type:<class 'tuple'>,-- metrics:{} type:<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "metrics_bits = MetricsCB_bits(MulticlassAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30704564-fab0-40cb-bf13-ff067bb8355e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MulticlassAccuracy': <torcheval.metrics.classification.accuracy.MulticlassAccuracy>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bits.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea18f77-d2bf-4bea-a36f-82ca230dc902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([<torcheval.metrics.classification.accuracy.MulticlassAccuracy object>, <torcheval.metrics.aggregation.mean.Mean object>])\n"
     ]
    }
   ],
   "source": [
    "print(metrics_bits.all_metrics.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f055c5-c049-49f9-bb25-9e4d187eeddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torcheval.metrics.classification.accuracy.MulticlassAccuracy>,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bits.ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952ab40-2f44-43d1-aafd-59b12b510e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torcheval.metrics.classification.accuracy.MulticlassAccuracy object>\n"
     ]
    }
   ],
   "source": [
    "for i in metrics_bits.ms:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6be2b7-2566-4fe0-ab0f-456ca55bf467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([<torcheval.metrics.classification.accuracy.MulticlassAccuracy object>, <torcheval.metrics.aggregation.mean.Mean object>])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bits.all_metrics.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c01f17-fbb8-4fe6-a5b8-136e7bec30e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bound method Metric.reset of <torcheval.metrics.classification.accuracy.MulticlassAccuracy object>>,\n",
       " <bound method Metric.reset of <torcheval.metrics.aggregation.mean.Mean object>>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.reset for o in metrics_bits.all_metrics.values()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
